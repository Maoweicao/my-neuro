# 从零训练大语言模型

源码来源：https://github.com/karpathy/nanoGPT

感谢 karpathy 提供了这么好用的模型训练源码。让大家可以在消费级显卡上面来从架构轻松训练LLM

对于为什么要从零，也就是从transformer的架构开始，甚至不是从预训练模型开始训练LLM？训练出来的模型可能需要1、2天。如果显卡的显存不够。模型的参数大小甚至可能还在非常小的规模级别（1B左右）为什么在当前的

时间线上，开源模型如此泛滥的时期还要来从头开始训练LLM？例如千问、智谱、书生、百川国外的gemma系列、llama系列等一众好用的开源模型。他们都用了非常多高质量的训练数据、以及大规模的显卡集群来精心炼制。产出

好用的模型，为什么不直接用他们的模型训练微调呢？

有两个原因，第一个原因是LLM-studio文件夹里面已经这样做了。所以想要直接微调开源的LLM去那里就可以了。

第二个原因才是关键。因为从零开始训练大模型更能完全的控制模型的整体风格。语言习惯。可能有些人不太理解这句话的涵义。当前的开源模型普遍来说，都是基于指令驱动，或者说是任务驱动。大部分的都是使用指令数据集。

我举一个示例：

```bash
{
  "指令": "将下面的句子翻译成英文",
  "输入": "今天天气很好",
  "输出": "The weather is very nice today."
}，
{
  "指令": "如何减肥",
  "输入": "",
  "输出": "减肥需要控制饮食和适当运动，你需要：1.记录每日饮食，了解自己的热量摄入情况。2.多走路、爬楼梯，增加日常活动量 3.xxxxx 4.xxxxx"
}
```


像上面的这种有明确任务的，就叫做指令数据集。核心就是教会模型听指令，问什么答什么。这种数据的好处非常明显。大大提高了模型的回复质量。可以做很多事情。例如润色文章、写报告、代码、扮演角色、做各种任务等

所以当下的开源模型基本上是指令数据集占比非常大的。因为核心的述求就是想让模型帮助自己做自己需要的事情。但是，这样有好也有坏。

坏的地方是，在大规模的指令数据训练下，模型整体的风格会统一化，也就是会按照训练的指令数据的风格说话，具体一点就是。假设你今天不想让模型只当一个工具AI了。想让模型可以和自己聊聊天。

然后你给他一个提示词：模仿可爱、体贴、温柔的AI和我对话。模型可能会尝试扮演模仿。但是由于训练的时候指令的数据占比过多，导致AI说出的内容会往自己的语言格式靠近，所以可能就会说出

冗长、喋喋不休的安慰关心的内容。恨不得一个回合就把所有想要说的东西都抛给你。不像是一个真实场景下，真人的那种对话体验。想要达到一个好的对话氛围和体验，你可能需要用非常多的提示词约束

警告、引导模型按照你的要求来说话。可能会用到各种的后处理技术。核心的原因就是模型本身基于上述数据训练后的特点。

但是可能也有人会说：这又不是没有处理方法。你刚刚不是也说了吗？提示词写好一些。背后的处理多花一些功夫不就行了啊？不也能达到和真人对话的那种效果啊？

我想说的是，确实可以这样做。而且效果确实很不错。例如麦麦那样的项目。就是把这一点做到了极其优秀的水平。但是问题是，这些都是基于了非常多的处理和精心设计的提示词。最重要的一点就是

用来实验的LLM本身的要求非常高。因为普通的小参数的模型，例如10B~20B的这种区间。你给他设定如此复杂的提示词，作用很有限。它会有非常明显的说话习惯，例如会在聊天中频繁的使用：1、2、3、4 这样的

举例说明。结尾总结、说话风格套路化，甚至聊多了就能猜到模型之后会说什么。

更不要说参数更小的模型了。

Re_Zero_LLM 意思就是从零开始的LLM 也就是真正的从零开始训练模型。在此之前，我想明确说明的事是，这并不是训练那种通用模型而设计的。是专门为了训练特色角色模型设计的。也就是说是训练

虚拟、为特定个性的LLM定制的。所以后续的优化会围绕如何训练出一个符合你想象的AI模型。它可能不擅长做任务、不擅长写代码、也润色不好什么文章。就是纯粹的训练一个理想中那样的角色。可以本地部署的永久的一个私有AI模型

当然，也不可能一点指令数据集和通用数据集都不用。但是比例可能会小很多。核心还是围绕如何让AI拜托公式化的对话风格。以及给出意想不到的真实有感情的回应。

当前开发中，























