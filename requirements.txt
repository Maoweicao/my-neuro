torch>=2.0.0
transformers>=4.36.0  
datasets>=2.14.0
peft>=0.7.0
accelerate>=0.24.0  
sentencepiece>=0.1.99  
protobuf>=4.24.0  
scipy>=1.11.0  
pyyaml>=6.0.1  
tqdm>=4.65.0  
numpy>=1.24.0
tokenizers>=0.15.0  
packaging>=23.0  