<!DOCTYPE html>
<html>
<head>
    <link href="https://fonts.googleapis.com/css2?family=Patrick+Hand&display=swap" rel="stylesheet">
    <title>Live2D桌宠与语音聊天</title>
    <style>
        body {
            margin: 0;
            padding: 0;
            background: transparent;
            overflow: hidden;
            user-select: none;
            -webkit-user-select: none;
        }

        #canvas {
            position: fixed;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
        }

        #subtitle-container {
            position: fixed;
            bottom: 20px;
            left: 70%;
            transform: translateX(-50%);
            max-width: 80%;
            padding: 10px 20px;
            border-radius: 10px;
            z-index: 1000;
            display: none;
            text-align: center;
            overflow-y: auto;
            word-wrap: break-word;
            white-space: pre-wrap;
        }

        #subtitle-text {
            color: white;
            font-size: 30px;
            margin: 0;
            font-family: 'Patrick Hand', 'ZCOOL QingKe HuangYou', sans-serif;
            line-height: 1.5;
            font-weight: 900;
            text-shadow: 
                  -0.5px -0.5px 0 black,
                  0.5px -0.5px 0 black,
                  -0.5px 0.5px 0 black,
                  1.5px 1.5px 0 black;
         }
    </style>
</head>
<body>
    <canvas id="canvas"></canvas>
    <div id="subtitle-container">
        <p id="subtitle-text"></p>
    </div>

    <script src="https://cubism.live2d.com/sdk-web/cubismcore/live2dcubismcore.min.js"></script>
    <script src="https://cdn.jsdelivr.net/gh/dylanNew/live2d/webgl/Live2D/lib/live2d.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/pixi.js@6.5.2/dist/browser/pixi.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/pixi-live2d-display/dist/index.min.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/pixi-live2d-display/dist/extra.min.js"></script>

    <script>
        const { ipcRenderer } = require('electron');
        const fs = require('fs');
        const path = require('path');
        const os = require('os');

        let subtitleTimeout = null;

        function showSubtitle(text, duration = null) {
            const container = document.getElementById('subtitle-container');
            const subtitleText = document.getElementById('subtitle-text');
            
            if (subtitleTimeout) {
                clearTimeout(subtitleTimeout);
                subtitleTimeout = null;
            }
            
            subtitleText.textContent = text;
            container.style.display = 'block';

            if (duration) {
                subtitleTimeout = setTimeout(() => {
                    hideSubtitle();
                }, duration);
            }
        }

        function hideSubtitle() {
            const container = document.getElementById('subtitle-container');
            container.style.display = 'none';
            if (subtitleTimeout) {
                clearTimeout(subtitleTimeout);
                subtitleTimeout = null;
            }
        }

        // 修改后的文本处理器 - 添加文字与音频同步功能
        class EnhancedTextProcessor {
            constructor(ttsUrl, onAudioDataCallback, onStartCallback, onEndCallback) {
                this.ttsUrl = ttsUrl;
                this.onAudioDataCallback = onAudioDataCallback;
                this.onStartCallback = onStartCallback;
                this.onEndCallback = onEndCallback;

                // 单一队列设计
                this.textSegmentQueue = [];    // 待处理的文本段
                this.audioDataQueue = [];      // 已获得音频数据但尚未播放
                
                // 处理状态标志
                this.isProcessing = false;     // 正在处理文本段
                this.isPlaying = false;        // 正在播放音频
                this.shouldStop = false;       // 停止标志
                
                // 音频处理相关
                this.audioContext = null;
                this.analyser = null;
                this.dataArray = null;
                this.currentAudio = null;
                
                // 标点符号定义
                this.punctuations = [',', '。', '，', '？', '!', '！', '；', ';', '：', ':'];
                
                // 当前要显示的完整文本
                this.currentFullText = '';
                
                // 临时存储未处理的文本片段
                this.pendingSegment = '';
                
                // 文字同步相关
                this.llmFullResponse = '';     // LLM返回的完整回复文本
                this.displayedText = '';       // 当前已经显示的文本
                this.currentSegmentText = '';  // 当前正在播放的音频段落对应的文本
                this.syncTextQueue = [];       // 文本段落队列，与音频段落队列对应
                
                // 启动处理线程
                this.startProcessingThread();
                this.startPlaybackThread();
            }

            // 初始化音频上下文
            async initAudioContext() {
                if (!this.audioContext) {
                    this.audioContext = new (window.AudioContext || window.webkitAudioContext)();
                    this.analyser = this.audioContext.createAnalyser();
                    this.analyser.fftSize = 256;
                    this.dataArray = new Uint8Array(this.analyser.frequencyBinCount);
                }
            }

            // 启动文本处理线程 - 顺序处理文本段
            startProcessingThread() {
                const processNextSegment = async () => {
                    if (this.shouldStop) return;
                    
                    // 当有文本段待处理且当前没有处理中的文本段时
                    if (this.textSegmentQueue.length > 0 && !this.isProcessing) {
                        this.isProcessing = true;
                        const segment = this.textSegmentQueue.shift();
                        
                        try {
                            // 将文本段添加到同步队列，用于后续文本动画显示
                            this.syncTextQueue.push(segment);
                            
                            // 处理单个文本段
                            const audioData = await this.convertTextToSpeech(segment);
                            if (audioData) {
                                // 将音频数据和对应的文本作为一个包加入队列
                                this.audioDataQueue.push({
                                    audio: audioData,
                                    text: segment
                                });
                            }
                        } catch (error) {
                            console.error('TTS处理错误:', error);
                        }
                        
                        this.isProcessing = false;
                    }
                    
                    // 继续检查队列
                    setTimeout(processNextSegment, 50);
                };
                
                // 开始处理循环
                processNextSegment();
            }

            // 启动音频播放线程 - 顺序播放音频
            startPlaybackThread() {
                const playNextAudio = async () => {
                    if (this.shouldStop) return;
                    
                    // 当有音频数据待播放且当前没有播放中的音频时
                    if (this.audioDataQueue.length > 0 && !this.isPlaying) {
                        const audioPackage = this.audioDataQueue.shift();
                        
                        // 设置当前段落的文本，用于文字动画
                        this.currentSegmentText = audioPackage.text;
                        
                        // 播放音频并同步显示文本
                        await this.playAudioWithTextSync(audioPackage.audio);
                    }
                    
                    // 继续检查队列
                    setTimeout(playNextAudio, 50);
                };
                
                // 开始播放循环
                playNextAudio();
            }

            // 将文本转换为语音
            async convertTextToSpeech(text) {
                try {
                    // 移除括号内容和星号包裹的内容用于TTS
                    const textForTTS = text
                        .replace(/（.*?）|\(.*?\)/g, '')  // 移除括号内容
                        .replace(/\*.*?\*/g, '');         // 移除星号包裹内容
                        
                    const response = await fetch(this.ttsUrl, {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json'
                        },
                        body: JSON.stringify({
                            text: textForTTS,
                            text_language: "zh"
                        })
                    });
                    
                    if (!response.ok) {
                        throw new Error('TTS请求失败: ' + response.status);
                    }
                    
                    return await response.blob();
                } catch (error) {
                    console.error('TTS转换错误:', error);
                    return null;
                }
            }

            // 播放单个音频片段，同时实现文本动画同步
            async playAudioWithTextSync(audioBlob) {
                if (!audioBlob) return;
                
                await this.initAudioContext();
                return new Promise((resolve) => {
                    if (this.shouldStop) {
                        resolve();
                        return;
                    }
                    
                    this.isPlaying = true;
                    const audioUrl = URL.createObjectURL(audioBlob);
                    const audio = new Audio(audioUrl);
                    this.currentAudio = audio;
                    
                    // 触发开始回调
                    if (this.onStartCallback) {
                        this.onStartCallback();
                    }
                    
                    // 设置音频分析
                    const source = this.audioContext.createMediaElementSource(audio);
                    source.connect(this.analyser);
                    this.analyser.connect(this.audioContext.destination);
                    
                    // 当前段落的文本动画
                    const segmentText = this.currentSegmentText;
                    const segmentLength = segmentText.length;
                    let charDisplayIndex = 0;
                    
                    // 动态显示文本的计时器
                    let textAnimInterval = null;
                    
                    // 更新AI的嘴巴动作
                    const updateMouth = () => {
                        if (this.shouldStop || !this.currentAudio) return;
                        
                        this.analyser.getByteFrequencyData(this.dataArray);
                        const sampleCount = this.dataArray.length / 2;
                        let sum = 0;
                        for (let i = 0; i < sampleCount; i++) {
                            sum += this.dataArray[i];
                        }
                        const average = sum / sampleCount;
                        
                        // 使用平方根函数使动画更自然
                        const mouthOpenValue = Math.pow((average / 256), 0.8) * 1;
                        
                        if (this.onAudioDataCallback) {
                            this.onAudioDataCallback(mouthOpenValue);
                        }
                        
                        // 持续更新
                        if (this.currentAudio) {
                            requestAnimationFrame(updateMouth);
                        }
                    };

                    // 开始文本动画
                    const startTextAnimation = () => {
                        // 计算每个字符显示的间隔时间（根据音频长度和文本长度）
                        const audioDuration = audio.duration * 1000; // 毫秒
                        let charInterval = audioDuration / segmentLength;
                        
                        // 设置最小和最大字符间隔，以确保动画自然
                        charInterval = Math.max(30, Math.min(200, charInterval));
                        
                        textAnimInterval = setInterval(() => {
                            if (charDisplayIndex < segmentLength) {
                                // 逐步增加显示的文本
                                charDisplayIndex++;
                                const displayRatio = charDisplayIndex / segmentLength;
                                
                                // 显示的文本 = 已经显示的文本 + 当前段落按比例显示的部分
                                const currentDisplay = this.displayedText + segmentText.substring(0, Math.floor(displayRatio * segmentLength));
                                
                                // 更新字幕显示
                                showSubtitle(`Fake Neuro: ${currentDisplay}`);
                            }
                        }, charInterval);
                    };
                    
                    audio.oncanplaythrough = () => {
                        startTextAnimation();
                    };
                    
                    audio.onplay = () => {
                        updateMouth();
                    };
                    
                    audio.onended = () => {
                        if (this.onAudioDataCallback) {
                            this.onAudioDataCallback(0); // 关闭嘴巴
                        }
                        
                        // 清除文本动画计时器
                        if (textAnimInterval) {
                            clearInterval(textAnimInterval);
                            textAnimInterval = null;
                        }
                        
                        // 音频播放完毕后，将当前段落全部显示
                        this.displayedText += this.currentSegmentText;
                        showSubtitle(`Fake Neuro: ${this.displayedText}`);
                        
                        URL.revokeObjectURL(audioUrl);
                        this.currentAudio = null;
                        this.isPlaying = false;
                        
                        // 检查是否所有文本都已处理和播放完成
                        if (this.audioDataQueue.length === 0 && 
                            this.textSegmentQueue.length === 0 && 
                            !this.isProcessing &&
                            this.pendingSegment.trim() === '') {
                            
                            // 修复：播放完成后，设置一个3秒的延迟然后隐藏字幕
                            setTimeout(() => {
                                hideSubtitle();
                            }, 1000);
                            
                            if (this.onEndCallback) {
                                this.onEndCallback();
                            }
                        }
                        
                        resolve();
                    };
                    
                    audio.onerror = (e) => {
                        console.error('音频播放错误:', e);
                        
                        // 清除文本动画计时器
                        if (textAnimInterval) {
                            clearInterval(textAnimInterval);
                            textAnimInterval = null;
                        }
                        
                        URL.revokeObjectURL(audioUrl);
                        this.currentAudio = null;
                        this.isPlaying = false;
                        resolve();
                    };
                    
                    // 播放
                    audio.play().catch(error => {
                        console.error('播放失败:', error);
                        
                        // 清除文本动画计时器
                        if (textAnimInterval) {
                            clearInterval(textAnimInterval);
                            textAnimInterval = null;
                        }
                        
                        this.currentAudio = null;
                        this.isPlaying = false;
                        resolve();
                    });
                });
            }

            // 添加流式文本，实时进行分段处理
            addStreamingText(text) {
                if (this.shouldStop) return;
                
                // 更新LLM的完整响应文本
                this.llmFullResponse += text;
                
                // 不再直接显示全部文本，而是保存起来供同步显示使用
                // 仅在用户说话时显示用户的文本
                
                // 将新文本追加到待处理的段落中
                this.pendingSegment += text;
                
                // 逐字符处理，遇到标点符号就分段
                let processedSegment = '';
                for (let i = 0; i < this.pendingSegment.length; i++) {
                    const char = this.pendingSegment[i];
                    processedSegment += char;
                    
                    // 遇到标点符号时分段
                    if (this.punctuations.includes(char) && processedSegment.trim()) {
                        this.textSegmentQueue.push(processedSegment);
                        processedSegment = '';
                    }
                }
                
                // 保存未处理完的文本段
                this.pendingSegment = processedSegment;
                
                // 如果处理了大量文本但没有遇到标点符号，强制分段
                if (this.pendingSegment.length > 30) {
                    this.textSegmentQueue.push(this.pendingSegment);
                    this.pendingSegment = '';
                }
            }
            
            // 完成流式文本处理，确保所有文本都被处理
            finalizeStreamingText() {
                // 确保任何剩余的文本都被处理
                if (this.pendingSegment.trim()) {
                    this.textSegmentQueue.push(this.pendingSegment);
                    this.pendingSegment = '';
                }
            }

            // 处理完整文本（兼容旧的调用方式）
            async processTextToSpeech(text) {
                if (!text.trim()) return;
                
                this.reset();
                this.llmFullResponse = text;
                
                // 不再直接显示文本，而是等待音频播放时显示
                
                // 分段处理文本
                let currentSegment = '';
                for (let char of text) {
                    currentSegment += char;
                    if (this.punctuations.includes(char) && currentSegment.trim()) {
                        this.textSegmentQueue.push(currentSegment);
                        currentSegment = '';
                    }
                }
                
                // 处理末尾没有标点的文本
                if (currentSegment.trim()) {
                    this.textSegmentQueue.push(currentSegment);
                }
            }

            // 重置所有状态
            reset() {
                this.llmFullResponse = '';
                this.displayedText = '';
                this.currentSegmentText = '';
                this.pendingSegment = '';
                this.syncTextQueue = [];
                
                // 停止当前播放
                if (this.currentAudio) {
                    this.currentAudio.pause();
                    this.currentAudio = null;
                }
                
                // 清空所有队列
                this.textSegmentQueue = [];
                this.audioDataQueue = [];
                
                // 重置状态
                this.isPlaying = false;
                this.isProcessing = false;
                this.shouldStop = false;
                
                // 重置嘴部动作
                if (this.onAudioDataCallback) {
                    this.onAudioDataCallback(0);
                }
            }

            // 立即停止所有处理
            stop() {
                this.shouldStop = true;
                this.reset();
                
                // 隐藏字幕
                hideSubtitle();
                
                if (this.onEndCallback) {
                    this.onEndCallback();
                }
            }
            
            // 判断是否正在播放
            isPlaying() {
                return this.isPlaying || this.isProcessing || this.textSegmentQueue.length > 0 || this.audioDataQueue.length > 0;
            }
        }

        class VoiceChatInterface {
            constructor(vadUrl, asrUrl, ttsProcessor) {
                this.API_KEY = 'xxxx';
                this.API_URL = 'http://localhost:6006/v2';
                this.vadUrl = vadUrl;
                this.asrUrl = asrUrl;
                this.ttsProcessor = ttsProcessor;
                this.isProcessingAudio = false;
                
                // 添加ASR锁定机制 - 在完成整个对话流程前不再接收新的语音输入
                this.asrLocked = false;
                
                // 上下文限制相关属性
                this.maxContextMessages = 11; // 默认保留最新的11条消息
                this.enableContextLimit = true; // 默认开启上下文限制
                
                // 添加截图相关的属性
                this.screenshotEnabled = true; // 默认开启截图功能
                this.screenshotPath = path.join(os.homedir(), 'Desktop', 'screenshot.jpg'); // 截图保存路径
                
                this.messages = [
                    {
                        'role': 'system',
                        'content': '你的名字叫fake neuro 你是一个傲娇腹黑，偶尔会展现一些温柔的AI，说话不要用1、2、3、4这样回复,你现在被制作成了一个LIVE 2D的2D模型，是我的电脑桌宠。你平时一般称呼我为魔方，最后说话简短一些，不要长。'
                    }
                ];
                this.setupAudioSystem();
            }

            async pauseRecording() {
                if (this.mediaStream) {
                    this.mediaStream.getTracks().forEach(track => track.enabled = false);
                }
                this.isProcessingAudio = true;
                console.log('Recording paused due to TTS playback');
            }

            async resumeRecording() {
                if (this.mediaStream) {
                    this.mediaStream.getTracks().forEach(track => track.enabled = true);
                }
                this.isProcessingAudio = false;
                
                // 重要：在恢复录音时解锁ASR，只有当整个对话流程完成后才解锁
                this.asrLocked = false;
                console.log('Recording resumed after TTS playback, ASR unlocked');
            }

            setContextLimit(enable) {
                this.enableContextLimit = enable;
                if (enable) {
                    this.trimMessages();
                }
            }

            setMaxContextMessages(count) {
                if (count < 1) throw new Error('最大消息数不能小于1');
                this.maxContextMessages = count;
                if (this.enableContextLimit) {
                    this.trimMessages();
                }
            }

            trimMessages() {
                if (!this.enableContextLimit) return;

                const systemMessages = this.messages.filter(msg => msg.role === 'system');
                const nonSystemMessages = this.messages.filter(msg => msg.role !== 'system');

                const recentMessages = nonSystemMessages.slice(-this.maxContextMessages);

                this.messages = [...systemMessages, ...recentMessages];
            }
            
            // 添加截图功能
            async takeScreenshot() {
                try {
                    // 请求主进程进行截图，不显示任何提示
                    const filepath = await ipcRenderer.invoke('take-screenshot', this.screenshotPath);
                    console.log('截图已保存:', filepath);
                    return filepath;
                } catch (error) {
                    console.error('截图错误:', error);
                    throw error;
                }
            }
            
            // 将图片转换为base64编码
            async imageToBase64(imagePath) {
                return new Promise((resolve, reject) => {
                    fs.readFile(imagePath, (err, data) => {
                        if (err) {
                            console.error('读取图片失败:', err);
                            reject(err);
                            return;
                        }
                        const base64Image = Buffer.from(data).toString('base64');
                        resolve(base64Image);
                    });
                });
            }
            
            // 判断是否需要截图
            async shouldTakeScreenshot(text) {
                if (!this.screenshotEnabled) return false;
                
                try {
                    const url = `http://localhost:6006/v4/check?text=${encodeURIComponent(text)}`;
                    const response = await fetch(url, {
                        method: 'POST',
                    });
                    
                    const data = await response.json();
                    const result = data["需要视觉"];
                    console.log(`截图判断结果: ${result}`);
                    
                    return result === "是";
                } catch (error) {
                    console.error('判断截图错误:', error);
                    return false;
                }
            }

            async setupAudioSystem() {
                this.audioContext = null;
                this.mediaStream = null;
                this.ws = null;
                this.SAMPLE_RATE = 16000;
                this.WINDOW_SIZE = 512;
                this.retryCount = 0;
                this.MAX_RETRIES = 5;

                this.audioBuffer = [];
                this.BUFFER_DURATION = 1000;
                this.BUFFER_SIZE = Math.floor(this.SAMPLE_RATE * (this.BUFFER_DURATION / 1000));
                
                this.isRecording = false;
                this.continuousBuffer = [];
                this.recordingStartIndex = 0;
                this.PRE_RECORD_TIME = 1;
                this.PRE_RECORD_SAMPLES = this.SAMPLE_RATE * this.PRE_RECORD_TIME;
                
                this.lastSpeechTime = 0;
                this.SILENCE_THRESHOLD = 500;
                this.silenceTimeout = null;

                try {
                    await this.setupWebSocket();
                } catch (error) {
                    console.error('音频系统设置错误:', error);
                }
            }

            async setupWebSocket() {
                if (this.ws && this.ws.readyState === WebSocket.OPEN) {
                    this.ws.close();
                }
                
                this.ws = new WebSocket(this.vadUrl);

                this.ws.onopen = async () => {
                    console.log('VAD WebSocket已连接');
                    this.retryCount = 0;
                };

                this.ws.onmessage = (event) => {
                    // 添加ASR锁定检查，如果锁定则忽略所有语音输入
                    if (this.isProcessingAudio || this.asrLocked) return; 
                    
                    const data = JSON.parse(event.data);
                    const isSpeaking = data.is_speech;

                    if (isSpeaking) {
                        this.handleSpeech();
                    } else {
                        this.handleSilence();
                    }
                };

                this.ws.onclose = () => {
                    console.log('VAD WebSocket已断开');
                    if (this.retryCount < this.MAX_RETRIES) {
                        this.retryCount++;
                        console.log(`尝试重新连接... (${this.retryCount}/${this.MAX_RETRIES})`);
                        setTimeout(() => this.setupWebSocket(), 1000);
                    }
                };

                this.ws.onerror = (error) => {
                    console.error('WebSocket错误:', error);
                };
            }

            handleSpeech() {
                // 检查ASR是否锁定，如果锁定则不处理语音
                if (this.isProcessingAudio || this.asrLocked) return; 
                
                this.lastSpeechTime = Date.now();
                
                if (this.silenceTimeout) {
                    clearTimeout(this.silenceTimeout);
                    this.silenceTimeout = null;
                }

                if (!this.isRecording) {
                    this.isRecording = true;
                    this.recordingStartIndex = this.continuousBuffer.length;
                }
            }

            handleSilence() {
                // 检查ASR是否锁定，如果锁定则不处理语音
                if (this.isProcessingAudio || this.asrLocked) return; 
                
                if (this.isRecording) {
                    const currentTime = Date.now();
                    const silenceDuration = currentTime - this.lastSpeechTime;
                    
                    if (!this.silenceTimeout) {
                        this.silenceTimeout = setTimeout(() => {
                            this.finishRecording();
                            this.silenceTimeout = null;
                        }, this.SILENCE_THRESHOLD);
                    }
                }
            }

            async startRecording() {
                try {
                    this.mediaStream = await navigator.mediaDevices.getUserMedia({ 
                        audio: {
                            channelCount: 1,
                            sampleRate: this.SAMPLE_RATE,
                            echoCancellation: true,
                            noiseSuppression: true
                        } 
                    });

                    this.audioContext = new AudioContext({ sampleRate: this.SAMPLE_RATE });
                    const microphone = this.audioContext.createMediaStreamSource(this.mediaStream);
                    const scriptNode = this.audioContext.createScriptProcessor(this.WINDOW_SIZE, 1, 1);

                    microphone.connect(scriptNode);
                    scriptNode.connect(this.audioContext.destination);

                    let lastSendTime = 0;
                    const MIN_SEND_INTERVAL = 1;

                    scriptNode.onaudioprocess = (e) => {
                        // 检查ASR是否锁定，如果锁定则跳过音频处理
                        if (this.isProcessingAudio || this.asrLocked) return; 
                        
                        const currentTime = Date.now();
                        const audioData = e.inputBuffer.getChannelData(0);
                        
                        this.continuousBuffer.push(...Array.from(audioData));
                        
                        if (this.continuousBuffer.length > this.SAMPLE_RATE * 3600) {
                            const excessSamples = this.continuousBuffer.length - this.SAMPLE_RATE * 3600;
                            this.continuousBuffer = this.continuousBuffer.slice(excessSamples);
                            if (this.isRecording) {
                                this.recordingStartIndex = Math.max(0, this.recordingStartIndex - excessSamples);
                            }
                        }
                        
                        if (this.ws && this.ws.readyState === WebSocket.OPEN && 
                            currentTime - lastSendTime >= MIN_SEND_INTERVAL) {
                            this.ws.send(audioData);
                            lastSendTime = currentTime;
                        }
                    };

                    console.log('音频处理已启动');
                } catch (err) {
                    console.error('启动音频错误:', err);
                }
            }

            stopRecording() {
                if (this.mediaStream) {
                    this.mediaStream.getTracks().forEach(track => track.stop());
                }
                if (this.ws) {
                    this.ws.close();
                }
                if (this.silenceTimeout) {
                    clearTimeout(this.silenceTimeout);
                }
            }

            async finishRecording() {
                // 检查ASR是否锁定，如果锁定则不处理录音
                if (!this.isRecording || this.isProcessingAudio || this.asrLocked) return;
                this.isRecording = false;
                
                // 重要：在开始处理录音时立即锁定ASR，防止二次接收
                this.asrLocked = true;
                console.log('ASR锁定：开始处理录音');
                
                const recordingEndIndex = this.continuousBuffer.length;
                const actualStartIndex = Math.max(0, this.recordingStartIndex - this.PRE_RECORD_SAMPLES);
                const recordedSamples = this.continuousBuffer.slice(actualStartIndex, recordingEndIndex);
                
                if (recordedSamples.length > this.SAMPLE_RATE * 0.5) {
                    const wavBlob = this.float32ToWav(new Float32Array(recordedSamples));
                    await this.processRecording(wavBlob);
                } else {
                    console.log("录音太短，丢弃");
                    // 即使丢弃录音也保持锁定，直到交互完成
                    // ASR锁定会在TTS播放完毕后解除
                    this.asrLocked = false;
                }
                
                this.continuousBuffer = this.continuousBuffer.slice(-this.PRE_RECORD_SAMPLES);
            }

            float32ToWav(samples) {
                const buffer = new ArrayBuffer(44 + samples.length * 2);
                const view = new DataView(buffer);
                
                this.writeString(view, 0, 'RIFF');
                view.setUint32(4, 36 + samples.length * 2, true);
                this.writeString(view, 8, 'WAVE');
                this.writeString(view, 12, 'fmt ');
                view.setUint32(16, 16, true);
                view.setUint16(20, 1, true);
                view.setUint16(22, 1, true);
                view.setUint32(24, this.SAMPLE_RATE, true);
                view.setUint32(28, this.SAMPLE_RATE * 2, true);
                view.setUint16(32, 2, true);
                view.setUint16(34, 16, true);
                this.writeString(view, 36, 'data');
                view.setUint32(40, samples.length * 2, true);

                this.floatTo16BitPCM(view, 44, samples);

                return new Blob([buffer], { type: 'audio/wav' });
            }

            writeString(view, offset, string) {
                for (let i = 0; i < string.length; i++) {
                    view.setUint8(offset + i, string.charCodeAt(i));
                }
            }

            floatTo16BitPCM(view, offset, input) {
                for (let i = 0; i < input.length; i++, offset += 2) {
                    const s = Math.max(-1, Math.min(1, input[i]));
                    view.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7FFF, true);
                }
            }

            async processRecording(audioBlob) {
                const formData = new FormData();
                formData.append('file', audioBlob, 'recording.wav');
                
                try {
                    const response = await fetch(this.asrUrl, {
                        method: 'POST',
                        body: formData
                    });

                    const result = await response.json();
                    if (result.status === 'success' && result.text) {
                        console.log("用户说:", result.text);
                        // 恢复显示用户ASR字幕的功能
                        showSubtitle(`用户: ${result.text}`, 3000);
                        await this.sendToLLM(result.text);
                    } else {
                        console.error('ASR失败:', result.message);
                        // 如果ASR失败，也要解锁ASR以允许用户重试
                        this.asrLocked = false;
                    }
                } catch (error) {
                    console.error('处理录音失败:', error);
                    // 如果处理失败，也要解锁ASR以允许用户重试
                    this.asrLocked = false;
                }
            }

            async sendToLLM(prompt) {
                try {
                    // 重置TTS处理器的状态
                    this.ttsProcessor.reset();
                    
                    // 清除之前的字幕，准备显示新对话
                    // 这里不直接隐藏字幕，因为用户的ASR字幕还在显示中
                    
                    let fullResponse = "";
                    let messagesForAPI = [...this.messages]; // 创建消息的副本用于API请求
                    
                    // 判断是否需要截图
                    const needScreenshot = await this.shouldTakeScreenshot(prompt);
                    
                    // 保存用户消息到上下文（只保存文本）
                    this.messages.push({'role': 'user', 'content': prompt});
                    
                    if (needScreenshot) {
                        try {
                            console.log("需要截图");
                            const screenshotPath = await this.takeScreenshot();
                            const base64Image = await this.imageToBase64(screenshotPath);
                            
                            // 创建包含图片的消息用于API请求（不存储到上下文）
                            messagesForAPI.pop(); // 移除刚刚添加的文本消息
                            messagesForAPI.push({
                                'role': 'user',
                                'content': [
                                    {'type': 'text', 'text': prompt},
                                    {'type': 'image_url', 'image_url': {'url': `data:image/jpeg;base64,${base64Image}`}}
                                ]
                            });
                        } catch (error) {
                            console.error("截图处理失败:", error);
                            // 如果截图失败，使用仅文本的消息
                            messagesForAPI = [...this.messages];
                        }
                    } else {
                        // 不需要截图，使用标准消息
                        messagesForAPI = [...this.messages];
                    }

                    // 在发送前进行消息裁剪
                    if (this.enableContextLimit) {
                        this.trimMessages();
                        
                        // 为API请求重建裁剪后的消息数组
                        const systemMessages = messagesForAPI.filter(msg => msg.role === 'system');
                        const userScreenshotMessage = needScreenshot ? [messagesForAPI[messagesForAPI.length - 1]] : [];
                        const contextMessages = this.messages.filter(msg => msg.role !== 'system');
                        
                        messagesForAPI = [...systemMessages, ...contextMessages];
                        
                        // 如果有截图消息并且它不在裁剪后的消息中，则添加回来
                        if (needScreenshot && userScreenshotMessage.length > 0) {
                            // 检查最后一条消息是否与截图消息文本相同
                            const lastMessage = messagesForAPI[messagesForAPI.length - 1];
                            if (lastMessage.role === 'user' && 
                                (lastMessage.content === prompt || 
                                (Array.isArray(lastMessage.content) && 
                                lastMessage.content[0].text === prompt))) {
                                // 替换最后一条消息为截图消息
                                messagesForAPI[messagesForAPI.length - 1] = userScreenshotMessage[0];
                            }
                        }
                    }

                    const response = await fetch(`${this.API_URL}/chat/completions`, {
                        method: 'POST',
                        headers: {
                            'Content-Type': 'application/json',
                            'Authorization': `Bearer ${this.API_KEY}`
                        },
                        body: JSON.stringify({
                            model: 'claude-3-7-sonnet-20250219',
                            messages: messagesForAPI,
                            stream: true
                        })
                    });

                    if (!response.ok) {
                        throw new Error("LLM服务器错误: " + response.statusText);
                    }

                    const reader = response.body.getReader();
                    const decoder = new TextDecoder("utf-8");

                    while (true) {
                        const { value, done } = await reader.read();
                        if (done) {
                            // 确保所有待处理文本都被发送到TTS
                            this.ttsProcessor.finalizeStreamingText();
                            break;
                        }

                        const text = decoder.decode(value);
                        const lines = text.split('\n');
                        
                        for (const line of lines) {
                            if (line.startsWith('data: ')) {
                                if (line.includes('[DONE]')) continue;
                                
                                try {
                                    const data = JSON.parse(line.slice(6));
                                    if (data.choices[0].delta.content) {
                                        const newContent = data.choices[0].delta.content;
                                        fullResponse += newContent;
                                        
                                        // 将新的文本片段传递给TTS处理器进行实时处理
                                        this.ttsProcessor.addStreamingText(newContent);
                                    }
                                } catch (e) {
                                    console.error('解析响应错误:', e);
                                }
                            }
                        }
                    }

                    if (fullResponse) {
                        // 只保存AI的文本回复到上下文
                        this.messages.push({'role': 'assistant', 'content': fullResponse});
                        
                        // 在接收响应后再次进行消息裁剪
                        if (this.enableContextLimit) {
                            this.trimMessages();
                        }
                    }
                } catch (error) {
                    console.error("LLM处理错误:", error);
                    showSubtitle("Sorry, an error occurred.", 3000);
                    // 出错时也要解锁ASR
                    this.asrLocked = false;
                    // 出错时也要隐藏字幕
                    setTimeout(() => hideSubtitle(), 3000);
                }
                
                // 注意：ASR锁定的解除会在TTS播放完成后通过resumeRecording()方法完成
                // 这确保了整个对话流程完成后才接收新的语音输入
            }
        }

        let interactionWidth, interactionHeight, interactionX, interactionY;
        let currentModel = null;

        // 设置嘴部动画回调函数
        function setMouthOpenY(v) {
            if (!currentModel) return;
            try {
                v = Math.max(0, Math.min(v, 3.0));
                const paramId = 'ParamMouthOpenY';
                const coreModel = currentModel.internalModel.coreModel;
                coreModel.setParameterValueById(paramId, v);
            } catch (error) {
                console.error('设置嘴型参数失败:', error);
            }
        }

        // 初始化增强版文本处理器
        const ttsProcessor = new EnhancedTextProcessor(
            'http://localhost:6006/v3',
            (value) => setMouthOpenY(value),  // 音频数据回调
            () => voiceChat && voiceChat.pauseRecording(),  // 开始回调
            () => voiceChat && voiceChat.resumeRecording()  // 结束回调 - 这里会解除ASR锁定
        );

        const INTRO_TEXT = "你好，我叫fake neuro。";
        let voiceChat = null;

        (async function main() {
            try {
                voiceChat = new VoiceChatInterface(
                    'ws://localhost:6006/v1/ws/vad',
                    'http://localhost:6006/v1/upload_audio',
                    ttsProcessor
                );

                const app = new PIXI.Application({
                    view: document.getElementById("canvas"),
                    autoStart: true,
                    transparent: true,
                    width: window.innerWidth * 2,
                    height: window.innerHeight * 2
                });

                app.stage.position.set(window.innerWidth / 2, window.innerHeight / 2);
                app.stage.pivot.set(window.innerWidth / 2, window.innerHeight / 2);

                const model = await PIXI.live2d.Live2DModel.from("Hiyori.model3.json");
                currentModel = model;
                app.stage.addChild(model);

                function updateInteractionArea() {
                    interactionWidth = model.width / 3;
                    interactionHeight = model.height * 0.7;
                    interactionX = model.x + (model.width - interactionWidth) / 2;
                    interactionY = model.y + (model.height - interactionHeight) / 2;
                }

                const scaleX = (window.innerWidth * 2.3) / model.width;
                const scaleY = (window.innerHeight * 2.3) / model.height;
                model.scale.set(Math.min(scaleX, scaleY));

                model.y = window.innerHeight * 0.8;
                model.x = window.innerWidth * 1.35;
                updateInteractionArea();

                model.interactive = true;

                const originalContainsPoint = model.containsPoint;
                model.containsPoint = function(point) {
                    return point.x >= interactionX &&
                           point.x <= interactionX + interactionWidth &&
                           point.y >= interactionY &&
                           point.y <= interactionY + interactionHeight;
                };

                let isDragging = false;
                let dragOffset = { x: 0, y: 0 };

                model.on('mousedown', (e) => {
                    const point = e.data.global;
                    if (model.containsPoint(point)) {
                        isDragging = true;
                        dragOffset.x = point.x - model.x;
                        dragOffset.y = point.y - model.y;
                        ipcRenderer.send('set-ignore-mouse-events', {
                            ignore: false
                        });
                    }
                });

                model.on('mousemove', (e) => {
                    if (isDragging) {
                        const newX = e.data.global.x - dragOffset.x;
                        const newY = e.data.global.y - dragOffset.y;
                        model.position.set(newX, newY);
                        updateInteractionArea();
                    }
                });

                window.addEventListener('mouseup', () => {
                    if (isDragging) {
                        isDragging = false;
                        setTimeout(() => {
                            if (!model.containsPoint(app.renderer.plugins.interaction.mouse.global)) {
                                ipcRenderer.send('set-ignore-mouse-events', {
                                    ignore: true,
                                    options: { forward: true }
                                });
                            }
                        }, 100);
                    }
                });

                model.on('mouseover', () => {
                    if (model.containsPoint(app.renderer.plugins.interaction.mouse.global)) {
                        ipcRenderer.send('set-ignore-mouse-events', {
                            ignore: false
                        });
                    }
                });

                model.on('mouseout', () => {
                    if (!isDragging) {
                        ipcRenderer.send('set-ignore-mouse-events', {
                            ignore: true,
                            options: { forward: true }
                        });
                    }
                });

                model.on('click', () => {
                    if (model.containsPoint(app.renderer.plugins.interaction.mouse.global) && model.internalModel) {
                        model.motion("Tap");
                        model.expression();
                    }
                });

                window.addEventListener('wheel', (e) => {
                    if (model.containsPoint(app.renderer.plugins.interaction.mouse.global)) {
                        e.preventDefault();

                        const scaleChange = e.deltaY > 0 ? 0.9 : 1.1;
                        const currentScale = model.scale.x;
                        const newScale = currentScale * scaleChange;

                        const minScale = model.scale.x * 0.3;
                        const maxScale = model.scale.x * 3.0;

                        if (newScale >= minScale && newScale <= maxScale) {
                            model.scale.set(newScale);

                            const oldWidth = model.width / scaleChange;
                            const oldHeight = model.height / scaleChange;
                            const deltaWidth = model.width - oldWidth;
                            const deltaHeight = model.height - oldHeight;

                            model.x -= deltaWidth / 2;
                            model.y -= deltaHeight / 2;
                            updateInteractionArea();
                        }
                    }
                }, { passive: false });

                window.addEventListener('resize', () => {
                    app.renderer.resize(window.innerWidth * 2, window.innerHeight * 2);
                    app.stage.position.set(window.innerWidth / 2, window.innerHeight / 2);
                    app.stage.pivot.set(window.innerWidth / 2, window.innerHeight / 2);
                    updateInteractionArea();
                });

                setTimeout(() => {
                    ttsProcessor.processTextToSpeech(INTRO_TEXT);
                }, 1000);

                setTimeout(() => {
                    voiceChat.startRecording();
                }, 3000);

            } catch (error) {
                console.error("加载模型错误:", error);
                console.error("错误详情:", error.message);
            }
        })();

        window.onbeforeunload = () => {
            if (voiceChat) {
                voiceChat.stopRecording();
            }
        };
    </script>
</body>
</html>